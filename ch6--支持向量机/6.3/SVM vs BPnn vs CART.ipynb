{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习-周志华-习题6.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 选择两个 UCI 数据集，分别用线性核和高斯核训练一个 SVM，并与BP 神经网络和 C4.5 决策树进行实验比较。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里就只用`sklearn`中自带的iris数据集来对比题中几个算法。这里数据集不大，只有150个样本，所以就不拿出额外的样本作为测试集了，进行`5-flod`交叉验证，最后验证集的平均准确率作为评价模型标准。\n",
    "\n",
    "--- \n",
    "- SVM将使用`sklearn.svm`\n",
    "- BP神经网络将使用`Tensorflow`实现\n",
    "- 关于C4.5。Python中貌似没有C4.5的包，在第四章写的决策树代码也并不是严格的C4.5，为了方便这里就还是使用`sklearn`吧。`sklearn`中决策树是优化的CART算法。\n",
    "\n",
    "---\n",
    "此外，各模型都进行了粗略的调参，不过在这里的`notebook`省略了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-28T12:49:23.837766Z",
     "start_time": "2024-10-28T12:49:20.745993Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score, cross_validate\n",
    "from sklearn import svm, tree\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import numpy as np\n",
    "# import tensorflow as tf"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、数据读入"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-28T12:49:26.848571Z",
     "start_time": "2024-10-28T12:49:26.800587Z"
    }
   },
   "source": [
    "iris = datasets.load_iris()\n",
    "X = pd.DataFrame(iris['data'], columns=iris['feature_names'])\n",
    "\n",
    "y = pd.Series(iris['target_names'][iris['target']])\n",
    "# y = pd.get_dummies(y)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:53:56.684932Z",
     "start_time": "2024-10-28T12:53:56.676997Z"
    }
   },
   "source": [
    "X.head()\n",
    "y.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    setosa\n",
       "1    setosa\n",
       "2    setosa\n",
       "3    setosa\n",
       "4    setosa\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、模型对比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 线性核SVM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:49:34.210075Z",
     "start_time": "2024-10-28T12:49:34.139621Z"
    }
   },
   "source": [
    "linear_svm = svm.SVC(C=1, kernel='linear')\n",
    "linear_scores = cross_validate(linear_svm, X, y, cv=5, scoring='accuracy')"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:49:36.053119Z",
     "start_time": "2024-10-28T12:49:36.047011Z"
    }
   },
   "source": [
    "linear_scores['test_score'].mean()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9800000000000001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3.2 高斯核SVM"
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-28T12:49:38.653912Z",
     "start_time": "2024-10-28T12:49:38.622147Z"
    }
   },
   "source": [
    "rbf_svm = svm.SVC(C=1)\n",
    "rbf_scores = cross_validate(rbf_svm, X, y, cv=5, scoring='accuracy')"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:49:39.925950Z",
     "start_time": "2024-10-28T12:49:39.918947Z"
    }
   },
   "source": [
    "rbf_scores['test_score'].mean()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666666"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3.3 BP神经网络"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "这里BP神经网络使用`tensorflow`实现，其实在`sklearn`中也有（当然在第五章也用`numpy`实现过，也可以用），不过这里因为个人原因还是使用`tensorflow`。。不过事实上如果为了答这道题，使用`sklearn`其实代码量会更少。\n",
    "\n",
    "---\n",
    "`tensorflow`里面没有现成的交叉验证的api（`tensorflow`中虽然也有其他机器学习算法的api，但它主要还是针对深度学习的工具，训练一个深度学习模型常常需要大量的数据，这个时候做交叉验证成本太高，所以深度学习中通常不做交叉验证，这也为什么`tensorflow`没有cv的原因），这里使用 `sklearn.model_selection.KFold`实现BP神经网络的交叉验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 定义模型，这里采用一层隐藏层的BP神经网络，神经元个数为16\n",
    "# x_input = tf.placeholder('float', shape=[None, 4])\n",
    "# y_input = tf.placeholder('float', shape=[None, 3])\n",
    "# \n",
    "# keep_prob = tf.placeholder('float', name='keep_prob')\n",
    "# \n",
    "# W1 = tf.get_variable('W1', [4, 16], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "# b1 = tf.get_variable('b1', [16], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "# \n",
    "# h1 = tf.nn.relu(tf.matmul(x_input, W1) + b1)\n",
    "# h1_dropout = tf.nn.dropout(h1, keep_prob=keep_prob, name='h1_dropout')\n",
    "# \n",
    "# W2 = tf.get_variable('W2', [16, 3], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "# b2 = tf.get_variable('b2', [3], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "# \n",
    "# y_output = tf.matmul(h1_dropout, W2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 定义训练步骤、准确率等\n",
    "# cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_output, labels=y_input))\n",
    "# \n",
    "# train_step = tf.train.AdamOptimizer(0.003).minimize(cost)\n",
    "# \n",
    "# correct_prediction = tf.equal(tf.argmax(y_output, 1), tf.argmax(y_input, 1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 将目标值one-hot编码\n",
    "# y_dummies = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "# init = tf.global_variables_initializer()\n",
    "# costs = []\n",
    "# accuracys = []\n",
    "# \n",
    "# for train, test in KFold(5, shuffle=True).split(X):\n",
    "#     sess.run(init)\n",
    "#     X_train = X.iloc[train, :]\n",
    "#     y_train = y_dummies.iloc[train, :]\n",
    "#     X_test = X.iloc[test, :]\n",
    "#     y_test = y_dummies.iloc[test, :]\n",
    "# \n",
    "#     for i in range(1000):\n",
    "#         sess.run(train_step, feed_dict={x_input: X_train, y_input: y_train, keep_prob: 0.3})\n",
    "# \n",
    "#     test_cost_, test_accuracy_ = sess.run([cost, accuracy],\n",
    "#                                           feed_dict={x_input: X_test, y_input: y_test, keep_prob: 1})\n",
    "#     accuracys.append(test_accuracy_)\n",
    "#     costs.append(test_cost_)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.93333334]\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "# print(accuracys)\n",
    "# print(np.mean(accuracys))"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T12:59:02.123568Z",
     "start_time": "2024-10-28T12:58:59.649642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_dummies = encoder.fit_transform(y.values.reshape(-1, 1))\n",
    "# y_dummies = pd.get_dummies(y)\n",
    "# 标准化特征数据\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 初始化 KFold 交叉验证\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "accuracys = []\n",
    "costs = []\n",
    "\n",
    "# 遍历每个训练/测试分割\n",
    "for train_index, test_index in kf.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y_dummies[train_index], y_dummies[test_index]\n",
    "\n",
    "    # 定义 MLPClassifier 模型\n",
    "    # 这里隐含层的神经元个数为 16，激活函数为 ReLU\n",
    "    # 与原始代码中的参数 keep_prob 类似，这里使用默认的 dropout\n",
    "    model = MLPClassifier(hidden_layer_sizes=(16,), activation='relu',\n",
    "                          solver='adam', learning_rate_init=0.003,\n",
    "                          max_iter=1000, random_state=0)\n",
    "\n",
    "    # 训练模型\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 预测\n",
    "    y_test_pred_probs = model.predict_proba(X_test)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # 计算准确率和损失\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_cost = log_loss(y_test, y_test_pred_probs)\n",
    "\n",
    "    accuracys.append(test_accuracy)\n",
    "    costs.append(test_cost)\n",
    "\n",
    "# 输出结果\n",
    "print(accuracys)\n",
    "print(np.mean(accuracys))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每折的准确率: [1.0, 0.6666666666666666, 0.9333333333333333, 0.7333333333333333, 1.0]\n",
      "平均准确率: 0.8666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3.4 CART"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cart_tree = tree.DecisionTreeClassifier()\n",
    "tree_scores = cross_validate(rbf_svm, X, y, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([ 0.00199413,  0.00256157,  0.00185156,  0.00298214,  0.0030067 ]),\n",
       " 'score_time': array([ 0.00099921,  0.00099659,  0.00114751,  0.00106406,  0.        ]),\n",
       " 'test_score': array([ 0.96666667,  1.        ,  0.96666667,  0.96666667,  1.        ]),\n",
       " 'train_score': array([ 0.98333333,  0.98333333,  0.99166667,  0.98333333,  0.975     ])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98000000000000009"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为`iris`数据原因，本身容易区分，这四个模型最终结果来看几乎一致（除了自己拿`tensorflow`写的BP神经网络，验证集上的准确率低了0.02）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
